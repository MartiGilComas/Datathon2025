{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class OurTransform:\n",
    "\n",
    "    # Constants distributed by processing\n",
    "    UNNECESSARY_LABELS = ['buyer_d1', 'buyer_d7', 'buyer_d14', 'buyer_d28', 'buy_d7', 'buy_d14',\n",
    "                            'buy_d28', 'iap_revenue_d14', 'iap_revenue_d28',\n",
    "                            'registration', 'retention_d1_to_d7', 'retention_d3_to_d7',\n",
    "                            'retention_d7_to_d14', 'retention_d1', 'retention_d3', 'retentiond7',]\n",
    "    UNNECESSARY_FEATURES = ['datetime', 'bundles_ins', 'city_hist', 'region_hist', 'dev_osv_hist', 'first_request_ts', 'first_request_ts_bundle', 'first_request_ts_category_bottom_taxonomy', 'iap_revenue_usd_bundle', 'last_buy', 'last_buy_ts_bundle', 'last_buy_ts_category', 'hour_ratio', 'last_ins', 'last_install_ts_bundle', 'last_install_ts_category', 'advertiser_actions_action_last_timestamp', 'user_actions_bundles_action_last_timestamp', 'new_bundles', 'num_buys_bundle', 'user_bundles', 'user_bundles_l28d', 'advertiser_bundle', 'carrier', 'region', 'dev_model', 'dev_osv', 'hour', 'release_date', 'release_msrp', 'weekday', 'user_actions_bundles_action_count']\n",
    "    \n",
    "    FILLNA_BYAVG_NAMES = ['avg_act_days', 'weekend_ratio', 'wifi_ratio']\n",
    "    FILLNA_BYMAX_NAMES = ['avg_days_ins', 'weeks_since_first_seen']\n",
    "\n",
    "    TO_SEPARATE_NAMES = ['bcat']\n",
    "    IGNORED_TO_SEPARATE = ['country_hist', 'bcat_bottom_taxonomy', 'bundles_cat', 'bundles_cat_bottom_taxonomy', 'cpm', 'cpm_pct_rk', 'ctr', 'ctr_pct_rk', 'dev_language_hist', 'iap_revenue_usd_category', 'iap_revenue_usd_category_bottom_taxonomy', 'num_buys_category', 'num_buys_category_bottom_taxonomy']\n",
    "    \n",
    "    ONE_HOT_ENCODER_NAMES = [ 'advertiser_category', 'country', 'dev_os']\n",
    "    IGNORED_ONE_HOT_ENCODER_NAMES = ['last_advertiser_action', 'advertiser_subcategory', 'advertiser_bottom_taxonomy_level', 'dev_make']\n",
    "\n",
    "    TO_REPLACE_BY_SUM = ['avg_daily_sessions', 'advertiser_actions_action_count', 'whale_users_bundle_total_num_buys', 'whale_users_bundle_total_revenue']\n",
    "    TO_REPLACE_BY_MEAN = ['avg_duration', 'rev_by_adv', 'rwd_prank', 'whale_users_bundle_num_buys_prank', 'whale_users_bundle_revenue_prank']\n",
    "    \n",
    "    # Constants distributed by type\n",
    "    LABEL_NAMES = ['buyer_d1', 'buyer_d7', 'buyer_d14', 'buyer_d28', 'buy_d7', 'buy_d14',\n",
    "                    'buy_d28', 'iap_revenue_d7', 'iap_revenue_d14', 'iap_revenue_d28',\n",
    "                    'registration', 'retention_d1_to_d7', 'retention_d3_to_d7',\n",
    "                    'retention_d7_to_d14', 'retention_d1', 'retention_d3', 'retentiond7']\n",
    "    REQUEST_RELATED_FEATURES = ['advertiser_bundle', 'advertiser_category', 'advertiser_subcategory',\n",
    "                                'advertiser_bottom_taxonomy_level', 'carrier', 'country', 'region',\n",
    "                                'dev_make', 'dev_model', 'dev_os', 'dev_osv', 'hour', 'release_date',\n",
    "                                'release_msrp', 'weekday']\n",
    "    USER_RELATED_FEATURES = ['avg_act_days', 'avg_daily_sessions',\n",
    "                            'avg_days_ins', 'avg_duration', 'bcat', 'bcat_bottom_taxonomy',\n",
    "                            'bundles_cat', 'bundles_cat_bottom_taxonomy', 'bundles_ins',\n",
    "                            'city_hist', 'country_hist', 'cpm', 'cpm_pct_rk', 'ctr', 'ctr_pct_rk',\n",
    "                            'dev_language_hist', 'dev_osv_hist', 'first_request_ts',\n",
    "                            'first_request_ts_bundle', 'first_request_ts_category_bottom_taxonomy',\n",
    "                            'hour_ratio', 'iap_revenue_usd_bundle', 'iap_revenue_usd_category',\n",
    "                            'iap_revenue_usd_category_bottom_taxonomy', 'last_buy',\n",
    "                            'last_buy_ts_bundle', 'last_buy_ts_category', 'last_ins',\n",
    "                            'last_install_ts_bundle', 'last_install_ts_category',\n",
    "                            'advertiser_actions_action_count',\n",
    "                            'advertiser_actions_action_last_timestamp',\n",
    "                            'user_actions_bundles_action_count',\n",
    "                            'user_actions_bundles_action_last_timestamp', 'last_advertiser_action',\n",
    "                            'new_bundles', 'num_buys_bundle', 'num_buys_category',\n",
    "                            'num_buys_category_bottom_taxonomy', 'region_hist', 'rev_by_adv',\n",
    "                            'rwd_prank', 'user_bundles', 'user_bundles_l28d', 'weekend_ratio',\n",
    "                            'weeks_since_first_seen', 'wifi_ratio',\n",
    "                            'whale_users_bundle_num_buys_prank', 'whale_users_bundle_revenue_prank',\n",
    "                            'whale_users_bundle_total_num_buys', 'whale_users_bundle_total_revenue']\n",
    "    AUX_NAMES = ['row_id', 'datetime']\n",
    "\n",
    "    # Camps\n",
    "    mean_dict: dict[str, float]\n",
    "    max_dict: dict[str, float]\n",
    "    categories_dict: dict[str, list[str]]\n",
    "\n",
    "    def __init__ (self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def fit_transform (self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = self.__remove_unnecessary_features(df, fit = True, test = False)\n",
    "        df = self.__remove_empty_rows(df, fit = True, test = False)\n",
    "        for col in self.FILLNA_BYMAX_NAMES:\n",
    "            self.max_dict = {}\n",
    "            df = self.__fillna_by_max(df, col = col, fit = True)\n",
    "        for col in self.FILLNA_BYAVG_NAMES:\n",
    "            self.mean_dict = {}\n",
    "            df = self.__fillna_by_mean(df, col = col, fit = True)\n",
    "        for col in self.TO_SEPARATE_NAMES:\n",
    "            self.categories_dict = {}\n",
    "            df = self.__value_hot_encoding(df, col = col, fit = True)\n",
    "        for col in self.ONE_HOT_ENCODER_NAMES:\n",
    "            df = self.__one_hot_encoding(df, col = col, fit = True)\n",
    "        for col in self.TO_REPLACE_BY_MEAN:\n",
    "            df = self.__replacement_by_mean(df, col = col, fit = True)\n",
    "        for col in self.TO_REPLACE_BY_SUM:\n",
    "            df = self.__replacement_by_sum(df, col = col, fit = True)\n",
    "        return df\n",
    "    \n",
    "    def transform (self, df: pd.DataFrame, test: bool = False) -> pd.DataFrame:\n",
    "        df = self.__remove_unnecessary_features(df, fit = False, test = test)\n",
    "        df = self.__remove_empty_rows(df, fit = False, test = test)\n",
    "        for col in self.FILLNA_BYMAX_NAMES:\n",
    "            df = self.__fillna_by_max(df, col = col, fit = False)\n",
    "        for col in self.FILLNA_BYAVG_NAMES:\n",
    "            df = self.__fillna_by_mean(df, col = col, fit = False)\n",
    "        for col in self.TO_SEPARATE_NAMES:\n",
    "            df = self.__value_hot_encoding(df, col = col, fit = False)\n",
    "        for col in self.ONE_HOT_ENCODER_NAMES:\n",
    "            df = self.__one_hot_encoding(df, col = col, fit = False)\n",
    "        for col in self.TO_REPLACE_BY_MEAN:\n",
    "            df = self.__replacement_by_mean(df, col = col, fit = False)\n",
    "        for col in self.TO_REPLACE_BY_SUM:\n",
    "            df = self.__replacement_by_sum(df, col = col, fit = False)\n",
    "        return df\n",
    "\n",
    "    def __remove_unnecessary_features (self, df: pd.DataFrame, fit: bool = True, test: bool = False) -> pd.DataFrame:\n",
    "        if test:\n",
    "            return df.drop(columns = self.UNNECESSARY_FEATURES\n",
    "                           + self.IGNORED_TO_SEPARATE\n",
    "                           + self.IGNORED_ONE_HOT_ENCODER_NAMES)\n",
    "        return df.drop(columns = self.UNNECESSARY_LABELS\n",
    "                       + self.UNNECESSARY_FEATURES\n",
    "                       + self.IGNORED_TO_SEPARATE\n",
    "                       + self.IGNORED_ONE_HOT_ENCODER_NAMES)\n",
    "    \n",
    "    def __remove_empty_rows (self, df: pd.DataFrame, fit: bool = True, test: bool = False) -> pd.DataFrame:\n",
    "        if test:\n",
    "            return df\n",
    "        # SPAGHETTTIIIIIIII\n",
    "        # user_df = df.loc[:, self.USER_RELATED_FEATURES]\\\n",
    "        #             .drop(columns = list(set(self.FILLNA_BYAVG_NAMES\n",
    "        #                                      + self.FILLNA_BYMAX_NAMES\n",
    "        #                                      + self.TO_SEPARATE_NAMES\n",
    "        #                                      + self.ONE_HOT_ENCODER_NAMES\n",
    "        #                                      + self.TO_REPLACE_BY_MEAN\n",
    "        #                                      + self.TO_REPLACE_BY_SUM)\\\n",
    "        #                                  .intersection(set(self.USER_RELATED_FEATURES))))\n",
    "        user_df = df.drop(columns = list(set(df.columns) - set(self.USER_RELATED_FEATURES)))\n",
    "        return df.loc[user_df.dropna(how = 'all').index, :]\n",
    "    \n",
    "    def __fillna_by_mean (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        if fit:\n",
    "            self.mean_dict[col] = df[col].mean()\n",
    "        df.loc[:, col] = df.loc[:, col].fillna(self.mean_dict[col])\n",
    "        return df\n",
    "    \n",
    "    def __fillna_by_max (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        if fit:\n",
    "            self.max_dict[col] = df[col].max()\n",
    "        df.loc[:, col] = df.loc[:, col].fillna(self.max_dict[col])\n",
    "        return df\n",
    "    \n",
    "    def __value_hot_encoding (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        OTHER = \"Other\"\n",
    "        if fit:\n",
    "            attrs = set()\n",
    "            for row in df[col]:\n",
    "                if isinstance(row, list):\n",
    "                    for cat, _ in row:\n",
    "                        attrs.add(cat.split(\"/\")[0])\n",
    "            attrs.add(OTHER)\n",
    "            self.categories_dict[col] = attrs\n",
    "        # Afegim columnes\n",
    "        for new_col in self.categories_dict[col]:\n",
    "            df[new_col] = 0\n",
    "        # Fem allÃ² d'afegir els valors\n",
    "        for idx, row in df.iterrows():\n",
    "            if isinstance(row[col], list):\n",
    "                for cat, val in row[\"bcat\"]:\n",
    "                    first_attr = cat.split(\"/\")[0]\n",
    "                    if first_attr in self.categories_dict[col]:\n",
    "                        df.at[idx, first_attr] += val\n",
    "                    else:\n",
    "                        df.at[idx, OTHER] += val\n",
    "        # Dropeja la original\n",
    "        return df.drop(columns = [col])\n",
    "    \n",
    "    def __one_hot_encoding (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        return pd.get_dummies(df, columns = [col])\n",
    "    \n",
    "    def __replacement_by_sum (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        df[col] = df[col].apply(lambda lst : sum(v for _, v in lst) if isinstance(lst, list) else 0)\n",
    "        return df\n",
    "    \n",
    "    def __replacement_by_mean (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        df[col] = df[col].apply(lambda lst : np.mean([v for _, v in lst]) if isinstance(lst, list) else 0)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18b7cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         17.0\n",
      "1          NaN\n",
      "2          NaN\n",
      "3          NaN\n",
      "4          NaN\n",
      "          ... \n",
      "121882     NaN\n",
      "121883     NaN\n",
      "121884     NaN\n",
      "121885     NaN\n",
      "121886     NaN\n",
      "Name: avg_days_ins, Length: 121887, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        iap_revenue_d7  avg_act_days  avg_daily_sessions  avg_days_ins  \\\n",
      "0             2.147718           2.0                   0          17.0   \n",
      "2             0.000000           4.0                   5          28.0   \n",
      "3             0.000000           3.0                   0          28.0   \n",
      "4             0.000000           7.0                   8          28.0   \n",
      "6             0.000000           4.0                   1          28.0   \n",
      "...                ...           ...                 ...           ...   \n",
      "121879        0.000000           7.0                   2           4.0   \n",
      "121880        0.000000           4.5                   0          28.0   \n",
      "121883        0.000000           2.0                   0          28.0   \n",
      "121885        0.000000           2.0                   1          28.0   \n",
      "121886        0.000000           7.0                   0          28.0   \n",
      "\n",
      "        avg_duration  advertiser_actions_action_count  rev_by_adv  rwd_prank  \\\n",
      "0                0.0                                0         0.0   0.423142   \n",
      "2              633.4                                0         0.0   0.344085   \n",
      "3                0.0                                0         0.0   0.383021   \n",
      "4             1352.0                                0         0.0   0.173239   \n",
      "6              255.0                                0         0.0   0.156279   \n",
      "...              ...                              ...         ...        ...   \n",
      "121879          28.0                                0         0.0   0.344960   \n",
      "121880           0.0                                0         0.0   0.374447   \n",
      "121883           0.0                                0         0.0   0.000000   \n",
      "121885         887.0                                0         0.0   0.000000   \n",
      "121886           0.0                                0         0.0   0.000000   \n",
      "\n",
      "        weekend_ratio  weeks_since_first_seen  ...  country_ve  country_vn  \\\n",
      "0            0.019802                     6.0  ...           0           0   \n",
      "2            0.399021                     6.0  ...           0           0   \n",
      "3            0.121547                     6.0  ...           0           0   \n",
      "4            0.293285                     6.0  ...           0           0   \n",
      "6            0.125000                     6.0  ...           0           0   \n",
      "...               ...                     ...  ...         ...         ...   \n",
      "121879       0.180190                     6.0  ...           0           0   \n",
      "121880       0.324675                     6.0  ...           0           0   \n",
      "121883       0.000000                     6.0  ...           0           0   \n",
      "121885       0.142857                     2.0  ...           0           0   \n",
      "121886       0.332903                     3.0  ...           0           0   \n",
      "\n",
      "        country_ws  country_xk  country_ye country_za  country_zm  country_zw  \\\n",
      "0                0           0           0          0           0           0   \n",
      "2                0           0           0          0           0           0   \n",
      "3                0           0           1          0           0           0   \n",
      "4                0           0           0          0           0           0   \n",
      "6                0           0           0          0           0           0   \n",
      "...            ...         ...         ...        ...         ...         ...   \n",
      "121879           0           0           0          0           0           0   \n",
      "121880           0           0           0          0           0           0   \n",
      "121883           0           0           0          0           0           0   \n",
      "121885           0           0           0          0           0           0   \n",
      "121886           0           0           0          0           0           0   \n",
      "\n",
      "        dev_os_android  dev_os_ios  \n",
      "0                    1           0  \n",
      "2                    0           1  \n",
      "3                    1           0  \n",
      "4                    1           0  \n",
      "6                    1           0  \n",
      "...                ...         ...  \n",
      "121879               0           1  \n",
      "121880               1           0  \n",
      "121883               1           0  \n",
      "121885               0           1  \n",
      "121886               1           0  \n",
      "\n",
      "[67707 rows x 264 columns]\n",
      "0              NaN\n",
      "1              NaN\n",
      "2         2.285714\n",
      "3         9.000000\n",
      "4              NaN\n",
      "            ...   \n",
      "124989         NaN\n",
      "124990         NaN\n",
      "124991         NaN\n",
      "124992         NaN\n",
      "124993         NaN\n",
      "Name: avg_days_ins, Length: 124994, dtype: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'avg_days_ins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     df \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(df)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     19\u001b[0m df\u001b[38;5;241m.\u001b[39mto_parquet(end_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/parquet-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [14], line 88\u001b[0m, in \u001b[0;36mOurTransform.transform\u001b[0;34m(self, df, test)\u001b[0m\n\u001b[1;32m     86\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__remove_empty_rows(df, fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, test \u001b[38;5;241m=\u001b[39m test)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFILLNA_BYMAX_NAMES:\n\u001b[0;32m---> 88\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fillna_by_max\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFILLNA_BYAVG_NAMES:\n\u001b[1;32m     90\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fillna_by_mean(df, col \u001b[38;5;241m=\u001b[39m col, fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [14], line 135\u001b[0m, in \u001b[0;36mOurTransform.__fillna_by_max\u001b[0;34m(self, df, col, fit)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_dict[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m--> 135\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[:, col] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:, col]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mKeyError\u001b[0m: 'avg_days_ins'"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "_ = dask.config.set({\"dataframe.convert-string\": False})\n",
    "\n",
    "dataset_path = \"smadex-challenge-predict-the-revenue/train/train\"\n",
    "end_path = \"smadex-challenge-predict-the-revenue/train_preprocess/train_preprocess\"\n",
    "ddf = dd.read_parquet(dataset_path)\n",
    "\n",
    "transformer = OurTransform()\n",
    "for i, part in enumerate(ddf.to_delayed()):\n",
    "    df = part.compute()\n",
    "    print(df[\"avg_days_ins\"])\n",
    "    if i == 0:\n",
    "        df = transformer.fit_transform(df)\n",
    "    else:\n",
    "        df = transformer.transform(df, test = False)\n",
    "    print(df)\n",
    "    df.to_parquet(end_path + f\"/parquet-{i}\")\n",
    "    if i == 4:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
