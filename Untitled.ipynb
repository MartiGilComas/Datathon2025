{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf8e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class OurTransform:\n",
    "\n",
    "    # Constants distributed by processing\n",
    "    UNNECESSARY_LABELS = ['buyer_d1', 'buyer_d7', 'buyer_d14', 'buyer_d28', 'buy_d7', 'buy_d14',\n",
    "                            'buy_d28', 'iap_revenue_d14', 'iap_revenue_d28',\n",
    "                            'registration', 'retention_d1_to_d7', 'retention_d3_to_d7',\n",
    "                            'retention_d7_to_d14', 'retention_d1', 'retention_d3', 'retentiond7',]\n",
    "    UNNECESSARY_FEATURES = ['datetime', 'bundles_ins', 'city_hist', 'region_hist', 'dev_osv_hist', 'first_request_ts', 'first_request_ts_bundle', 'first_request_ts_category_bottom_taxonomy', 'iap_revenue_usd_bundle', 'last_buy', 'last_buy_ts_bundle', 'last_buy_ts_category', 'hour_ratio', 'last_ins', 'last_install_ts_bundle', 'last_install_ts_category', 'advertiser_actions_action_last_timestamp', 'user_actions_bundles_action_last_timestamp', 'new_bundles', 'num_buys_bundle', 'user_bundles', 'user_bundles_l28d', 'advertiser_bundle', 'carrier', 'region', 'dev_model', 'dev_osv', 'hour', 'release_date', 'release_msrp', 'weekday', 'user_actions_bundles_action_count']\n",
    "    \n",
    "    FILLNA_BYAVG_NAMES = ['avg_act_days', 'weekend_ratio', 'wifi_ratio']\n",
    "    FILLNA_BYMAX_NAMES = ['avg_days_ins', 'weeks_since_first_seen']\n",
    "\n",
    "    TO_SEPARATE_NAMES = ['bcat']\n",
    "    IGNORED_TO_SEPARATE = ['country_hist', 'bcat_bottom_taxonomy', 'bundles_cat', 'bundles_cat_bottom_taxonomy', 'cpm', 'cpm_pct_rk', 'ctr', 'ctr_pct_rk', 'dev_language_hist', 'iap_revenue_usd_category', 'iap_revenue_usd_category_bottom_taxonomy', 'num_buys_category', 'num_buys_category_bottom_taxonomy']\n",
    "    \n",
    "    ONE_HOT_ENCODER_NAMES = []\n",
    "    IGNORED_ONE_HOT_ENCODER_NAMES = ['advertiser_category', 'country', 'dev_os', 'last_advertiser_action', 'advertiser_subcategory', 'advertiser_bottom_taxonomy_level', 'dev_make']\n",
    "\n",
    "    TO_REPLACE_BY_SUM = ['avg_daily_sessions', 'advertiser_actions_action_count', 'whale_users_bundle_total_num_buys', 'whale_users_bundle_total_revenue']\n",
    "    TO_REPLACE_BY_MEAN = ['avg_duration', 'rev_by_adv', 'rwd_prank', 'whale_users_bundle_num_buys_prank', 'whale_users_bundle_revenue_prank']\n",
    "    \n",
    "    # Constants distributed by type\n",
    "    LABEL_NAMES = ['buyer_d1', 'buyer_d7', 'buyer_d14', 'buyer_d28', 'buy_d7', 'buy_d14',\n",
    "                    'buy_d28', 'iap_revenue_d7', 'iap_revenue_d14', 'iap_revenue_d28',\n",
    "                    'registration', 'retention_d1_to_d7', 'retention_d3_to_d7',\n",
    "                    'retention_d7_to_d14', 'retention_d1', 'retention_d3', 'retentiond7']\n",
    "    REQUEST_RELATED_FEATURES = ['advertiser_bundle', 'advertiser_category', 'advertiser_subcategory',\n",
    "                                'advertiser_bottom_taxonomy_level', 'carrier', 'country', 'region',\n",
    "                                'dev_make', 'dev_model', 'dev_os', 'dev_osv', 'hour', 'release_date',\n",
    "                                'release_msrp', 'weekday']\n",
    "    USER_RELATED_FEATURES = ['avg_act_days', 'avg_daily_sessions',\n",
    "                            'avg_days_ins', 'avg_duration', 'bcat', 'bcat_bottom_taxonomy',\n",
    "                            'bundles_cat', 'bundles_cat_bottom_taxonomy', 'bundles_ins',\n",
    "                            'city_hist', 'country_hist', 'cpm', 'cpm_pct_rk', 'ctr', 'ctr_pct_rk',\n",
    "                            'dev_language_hist', 'dev_osv_hist', 'first_request_ts',\n",
    "                            'first_request_ts_bundle', 'first_request_ts_category_bottom_taxonomy',\n",
    "                            'hour_ratio', 'iap_revenue_usd_bundle', 'iap_revenue_usd_category',\n",
    "                            'iap_revenue_usd_category_bottom_taxonomy', 'last_buy',\n",
    "                            'last_buy_ts_bundle', 'last_buy_ts_category', 'last_ins',\n",
    "                            'last_install_ts_bundle', 'last_install_ts_category',\n",
    "                            'advertiser_actions_action_count',\n",
    "                            'advertiser_actions_action_last_timestamp',\n",
    "                            'user_actions_bundles_action_count',\n",
    "                            'user_actions_bundles_action_last_timestamp', 'last_advertiser_action',\n",
    "                            'new_bundles', 'num_buys_bundle', 'num_buys_category',\n",
    "                            'num_buys_category_bottom_taxonomy', 'region_hist', 'rev_by_adv',\n",
    "                            'rwd_prank', 'user_bundles', 'user_bundles_l28d', 'weekend_ratio',\n",
    "                            'weeks_since_first_seen', 'wifi_ratio',\n",
    "                            'whale_users_bundle_num_buys_prank', 'whale_users_bundle_revenue_prank',\n",
    "                            'whale_users_bundle_total_num_buys', 'whale_users_bundle_total_revenue']\n",
    "    AUX_NAMES = ['row_id', 'datetime']\n",
    "\n",
    "    # Camps\n",
    "    mean_dict: dict[str, float]\n",
    "    max_dict: dict[str, float]\n",
    "    categories_dict: dict[str, list[str]]\n",
    "\n",
    "    def __init__ (self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def fit_transform (self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = self.__remove_unnecessary_features(df, fit = True, test = False)\n",
    "        df = self.__remove_empty_rows(df, fit = True, test = False)\n",
    "        self.max_dict = {}\n",
    "        for col in self.FILLNA_BYMAX_NAMES:\n",
    "            df = self.__fillna_by_max(df, col = col, fit = True)\n",
    "        self.mean_dict = {}\n",
    "        for col in self.FILLNA_BYAVG_NAMES:\n",
    "            df = self.__fillna_by_mean(df, col = col, fit = True)\n",
    "        self.categories_dict = {}\n",
    "        for col in self.TO_SEPARATE_NAMES:\n",
    "            df = self.__value_hot_encoding(df, col = col, fit = True)\n",
    "        for col in self.ONE_HOT_ENCODER_NAMES:\n",
    "            df = self.__one_hot_encoding(df, col = col, fit = True)\n",
    "        for col in self.TO_REPLACE_BY_MEAN:\n",
    "            df = self.__replacement_by_mean(df, col = col, fit = True)\n",
    "        for col in self.TO_REPLACE_BY_SUM:\n",
    "            df = self.__replacement_by_sum(df, col = col, fit = True)\n",
    "        return df\n",
    "    \n",
    "    def transform (self, df: pd.DataFrame, test: bool = False) -> pd.DataFrame:\n",
    "        df = self.__remove_unnecessary_features(df, fit = False, test = test)\n",
    "        df = self.__remove_empty_rows(df, fit = False, test = test)\n",
    "        for col in self.FILLNA_BYMAX_NAMES:\n",
    "            df = self.__fillna_by_max(df, col = col, fit = False)\n",
    "        for col in self.FILLNA_BYAVG_NAMES:\n",
    "            df = self.__fillna_by_mean(df, col = col, fit = False)\n",
    "        for col in self.TO_SEPARATE_NAMES:\n",
    "            df = self.__value_hot_encoding(df, col = col, fit = False)\n",
    "        for col in self.ONE_HOT_ENCODER_NAMES:\n",
    "            df = self.__one_hot_encoding(df, col = col, fit = False)\n",
    "        for col in self.TO_REPLACE_BY_MEAN:\n",
    "            df = self.__replacement_by_mean(df, col = col, fit = False)\n",
    "        for col in self.TO_REPLACE_BY_SUM:\n",
    "            df = self.__replacement_by_sum(df, col = col, fit = False)\n",
    "        return df\n",
    "\n",
    "    def __remove_unnecessary_features (self, df: pd.DataFrame, fit: bool = True, test: bool = False) -> pd.DataFrame:\n",
    "        # if test:\n",
    "        #     return df.drop(columns = self.UNNECESSARY_FEATURES\n",
    "        #                    + self.IGNORED_TO_SEPARATE\n",
    "        #                    + self.IGNORED_ONE_HOT_ENCODER_NAMES)\n",
    "        return df.drop(columns = self.UNNECESSARY_FEATURES\n",
    "                       + self.IGNORED_TO_SEPARATE\n",
    "                       + self.IGNORED_ONE_HOT_ENCODER_NAMES)\n",
    "    \n",
    "    def __remove_empty_rows (self, df: pd.DataFrame, fit: bool = True, test: bool = False) -> pd.DataFrame:\n",
    "        if test:\n",
    "            return df\n",
    "        # SPAGHETTTIIIIIIII\n",
    "        # user_df = df.loc[:, self.USER_RELATED_FEATURES]\\\n",
    "        #             .drop(columns = list(set(self.FILLNA_BYAVG_NAMES\n",
    "        #                                      + self.FILLNA_BYMAX_NAMES\n",
    "        #                                      + self.TO_SEPARATE_NAMES\n",
    "        #                                      + self.ONE_HOT_ENCODER_NAMES\n",
    "        #                                      + self.TO_REPLACE_BY_MEAN\n",
    "        #                                      + self.TO_REPLACE_BY_SUM)\\\n",
    "        #                                  .intersection(set(self.USER_RELATED_FEATURES))))\n",
    "        user_df = df.drop(columns = list(set(df.columns) - set(self.USER_RELATED_FEATURES)))\n",
    "        return df.loc[user_df.dropna(how = 'all').index, :]\n",
    "    \n",
    "    def __fillna_by_mean (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        if fit:\n",
    "            self.mean_dict[col] = df[col].mean()\n",
    "        df.loc[:, col] = df.loc[:, col].fillna(self.mean_dict[col])\n",
    "        return df\n",
    "    \n",
    "    def __fillna_by_max (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        if fit:\n",
    "            self.max_dict[col] = df[col].max()\n",
    "        df.loc[:, col] = df.loc[:, col].fillna(self.max_dict[col])\n",
    "        return df\n",
    "    \n",
    "    def __value_hot_encoding (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        OTHER = \"Other\"\n",
    "        if fit:\n",
    "            attrs = set()\n",
    "            for row in df[col]:\n",
    "                if isinstance(row, list):\n",
    "                    for cat, _ in row:\n",
    "                        attrs.add(cat.split(\"/\")[0])\n",
    "            attrs.add(OTHER)\n",
    "            self.categories_dict[col] = attrs\n",
    "        # Afegim columnes\n",
    "        for new_col in self.categories_dict[col]:\n",
    "            df[new_col] = 0\n",
    "        # Fem allÃ² d'afegir els valors\n",
    "        for idx, row in df.iterrows():\n",
    "            if isinstance(row[col], list):\n",
    "                for cat, val in row[\"bcat\"]:\n",
    "                    first_attr = cat.split(\"/\")[0]\n",
    "                    if first_attr in self.categories_dict[col]:\n",
    "                        df.at[idx, first_attr] += val\n",
    "                    else:\n",
    "                        df.at[idx, OTHER] += val\n",
    "        # Dropeja la original\n",
    "        return df.drop(columns = [col])\n",
    "    \n",
    "    def __one_hot_encoding (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        OTHER = \"other\"\n",
    "        if fit:\n",
    "            df[col] = df[col].fillna(OTHER)\n",
    "            self.categories_dict[col] = list(col + \"_\" + df[col].unique())\n",
    "            self.categories_dict[col].append(col + \"_\" + OTHER)\n",
    "            self.categories_dict[col] = [c.lower() for c in self.categories_dict[col]]\n",
    "            print(self.categories_dict[col])\n",
    "            df = pd.get_dummies(df, columns = [col])\n",
    "        else:\n",
    "            for new_col in self.categories_dict[col]:\n",
    "                df[new_col] = 0\n",
    "            for idx, row in df.iterrows():\n",
    "                first_attr = row[col]\n",
    "                if first_attr in self.categories_dict[col]:\n",
    "                    df.at[idx, first_attr] = 1\n",
    "                else:\n",
    "                    df.at[idx, OTHER] = 1\n",
    "            df = df.drop(columns = [col])\n",
    "            for new_col in self.categories_dict[col]:\n",
    "                print(df[new_col].value_counts())\n",
    "        return df\n",
    "    \n",
    "    def __replacement_by_sum (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        df[col] = df[col].apply(lambda lst : sum(v for _, v in lst) if isinstance(lst, list) else 0)\n",
    "        return df\n",
    "    \n",
    "    def __replacement_by_mean (self, df: pd.DataFrame, col: str, fit: bool = True) -> pd.DataFrame:\n",
    "        df[col] = df[col].apply(lambda lst : np.mean([v for _, v in lst]) if isinstance(lst, list) else 0)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b7cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "_ = dask.config.set({\"dataframe.convert-string\": False})\n",
    "\n",
    "dataset_path = \"smadex-challenge-predict-the-revenue/train/train\"\n",
    "end_path = \"smadex-challenge-predict-the-revenue/train_preprocess/train_preprocess\"\n",
    "ddf = dd.read_parquet(dataset_path)\n",
    "\n",
    "transformer = OurTransform()\n",
    "for i, part in enumerate(ddf.to_delayed()):\n",
    "    df = part.compute()\n",
    "    if i == 0:\n",
    "        df = transformer.fit_transform(df)\n",
    "    else:\n",
    "        df = transformer.transform(df, test = False)\n",
    "    df.to_parquet(end_path + f\"/parquet-{i}\")\n",
    "    if i == 4:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
